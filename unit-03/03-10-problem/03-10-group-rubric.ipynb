{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORLwjdtwEAUhshPNIodmRz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Rubric for Group Report on Empirical Models  \n",
        "**Total: 20 Points (5 categories, 1-4 point scale per category)**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Data Selection and Description (4 points)\n",
        "This section evaluates the relevance of the dataset and the clarity of its description.\n",
        "\n",
        "- **4**: The dataset is highly relevant, meaning it is appropriate for empirical modeling (e.g., has enough data points, shows non-linear behavior, and is suitable for fitting a model). The source is clearly cited, and the group thoroughly explains the dataset, including its context, origin, and any notable features.\n",
        "- **3**: The dataset is mostly relevant, but may have minor shortcomings, such as a smaller sample size or less clear applicability to modeling. The description is clear but lacks depth in certain areas.\n",
        "- **2**: The dataset is somewhat relevant but may have significant issues (e.g., not enough data points, unclear relationship for modeling). The description of the dataset is vague or lacks important details.\n",
        "- **1**: The dataset is irrelevant to the problem, lacks sufficient data points, or is poorly described, with no citation or context provided.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Model Selection and Description (4 points)\n",
        "This section evaluates the appropriateness of the model selected to fit the data and the clarity of the explanation, including proper mathematical representation.\n",
        "\n",
        "- **4**: The group selects an appropriate, non-linear model that fits the data. The model is clearly explained, including a well-written mathematical description using LaTeX. Parameters of the model are clearly defined, and units are included where appropriate.\n",
        "- **3**: The selected model is reasonable but may not be the best choice for the data, or the explanation lacks some clarity. LaTeX formatting is mostly correct, but there are minor errors. Model parameters are identified but may lack full explanation.\n",
        "- **2**: The model is not well-suited to the data or is poorly explained. The use of LaTeX is limited or contains several mistakes. Parameters are vaguely defined or incomplete.\n",
        "- **1**: The model is inappropriate or not explained at all. Little to no effort is made to describe it mathematically or clarify its parameters.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Model Implementation in Python and Best-Fit Parameters (4 points)\n",
        "This section focuses on whether the model was correctly implemented in Python, with a proper fit to the data and correct handling of initial parameter guesses.\n",
        "\n",
        "- **4**: The model is fully and correctly implemented in Python. The group successfully determines the best-fit parameters, and the initial guesses for parameters are reasonable and well-chosen, leading to a robust fit.\n",
        "- **3**: The model is implemented in Python with some minor issues, but it still fits the data reasonably well. Initial guesses for parameters are generally good but could be improved to produce a better fit.\n",
        "- **2**: The model is implemented, but significant issues exist with the fitting process or the selection of initial guesses, resulting in a poor fit or incorrect parameters.\n",
        "- **1**: The model is not implemented correctly, or no meaningful fitting process is completed. Initial guesses are inappropriate, and the code does not produce valid results.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Code for Plotting Data and Model (4 points)\n",
        "This section evaluates the quality of the code used to generate plots of the data and the model, focusing on clarity and completeness of the plots.\n",
        "\n",
        "- **4**: The code produces clear, well-labeled plots of both the data and the model. Titles, axis labels (with units), and legends are all properly included, making the plot easy to interpret.\n",
        "- **3**: The code produces plots, but they may lack some labeling or clarity (e.g., missing units on axes, incomplete titles). The plot is still interpretable but could be improved.\n",
        "- **2**: The plots are incomplete or poorly labeled, making them difficult to interpret. Important information, such as axis labels or titles, is missing.\n",
        "- **1**: No plots are generated, or the plots are so poorly labeled and formatted that they are not useful for interpreting the data and model.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Writing and Organization (4 points)\n",
        "This section evaluates the overall clarity, organization, and quality of writing in the report.\n",
        "\n",
        "- **4**: The report is exceptionally well-organized and free from grammatical errors. The writing is clear, logical, and easy to follow. All sections flow naturally and support the reader’s understanding of the group's work.\n",
        "- **3**: The report is mostly well-organized, with a few minor issues in structure or clarity. There are occasional grammatical errors, but they do not significantly detract from the overall readability.\n",
        "- **2**: The report lacks structure, making it difficult to follow. Multiple grammatical errors impact the readability and professionalism of the document.\n",
        "- **1**: The report is poorly written, disorganized, and filled with grammatical errors. It is difficult to understand the group’s work due to the poor quality of writing.\n"
      ],
      "metadata": {
        "id": "K-cA10g5c0tv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This rubric was written and edited with assistance from [generative AI](https://chatgpt.com/share/66fb40f6-116c-8004-86f2-017dd9564e72)."
      ],
      "metadata": {
        "id": "w_GYXrdedTZh"
      }
    }
  ]
}