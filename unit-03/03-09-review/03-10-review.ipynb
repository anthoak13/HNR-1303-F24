{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3 Assessment - Empirical Models\n",
    "\n",
    "## Instructions\n",
    "\n",
    "In this assessment, you are going to develop an emperical model by fitting a curve to data, and you will use your model to make predictions.\n",
    "\n",
    "Scores are determined by:\n",
    "\n",
    "- Successfully starting the C Level = 50 pts\n",
    "- Perfectly completing the C Level = 75 pts\n",
    "- Perfectly completing the B and C Levels = 85 pts\n",
    "- Perfectly completing the A, B, and C Levels = 100 pts\n",
    "\n",
    "You may use your Colab notebooks, our textbook, my notebook solutions, and any links to web sites I provide. (You may not use any other person or web site or book or resource, in general.) \n",
    "\n",
    "You may ask me for help **once**; however, you may ask for clarification as often as needed.\n",
    "\n",
    "Add additional cells for both code and markdown as needed. Write answers to questions in narrative form in markdown. You may print values you need in your code, and then use these values in a written response.\n",
    "\n",
    "All graphs should have correct titles and axis labels (with units).\n",
    "\n",
    "## Grade\n",
    "\n",
    "<font color=\"green\"></font>\n",
    "\n",
    "Level | Grade | Comment\n",
    "--- | --- | ---\n",
    "C (75 pts) | | \n",
    "B (10 pts) | | \n",
    "A (15 pts) | | \n",
    "Total | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level C\n",
    "\n",
    "## Exercise 0\n",
    "\n",
    "1. Save a copy of this notebook to Google Drive. Have you already shared your Google Colabortory folder with \"hpuphysicsdepartment@gmail.com\"? If not, then be sure to share your folder.\n",
    "\n",
    "2. Add a text cell above and type your name as a level one heading in markdown. (A level one heading starts with # on its own line.)\n",
    "\n",
    "3. Run the `import` statements below to add packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #used for arrays and numerical functions\n",
    "import pandas as pd #used for reading a data file\n",
    "import matplotlib.pyplot as plt #used for graphing\n",
    "from io import StringIO #used to convert string to a dataframe\n",
    "from scipy.optimize import curve_fit #used to find the fit parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tempature of a solution increases, the amount of solute that can be disolved increases. This [data set](https://raw.githubusercontent.com/anthoak13/HNR-1303-F23/main/unit-03/03-10-problem/solubility.txt) ([source](https://pubs.acs.org/doi/10.1021/je00045a020)) shows the amount of sodium chloride (measured in g) that can be disolved in 100 g of a particular water-based solvent. Read the data and graph the amount of sodium chloride that can be disolved as a function of temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data in Exercise 1, do a linear curve fit and print the best-fit parameters for solubility as a function of temperature. Plot the best-fit curve and the data on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your curve-fit, predict the amount of NaCl that can be disolved at 80 $\\text{C}^\\circ$, and predict predict the amount of NaCl that can be disolved at 45 $\\text{C}^\\circ$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Using your curve-fit, predict the amount of NaCl that can be disolved at 100 $\\text{C}^\\circ$, and predict predict the amount of NaCl that can be disolved at 0 $\\text{C}^\\circ$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "What predictions from the last two exercises do you believe are valid? Why do you believe those predictions are valid but the other predictions are not? What additional data or modification to the model would you need to make to predict the solubility at each of the temperatures in the above exercises?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level B\n",
    "\n",
    "As the name \"Normal\" distribution implies, Gaussian distributions crop up all over the place in data analysis. This is due in large part to the Central Limit Theorem. In the Unit 2 assesment (level B), we modeled a fundraiser for a club. We were asking where a ball dropped down a Galton Board would land. When we plotted the distribution of the final x-position of the balls dropped we found a Gaussian distribution. \n",
    "\n",
    "[This file](https://raw.githubusercontent.com/anthoak13/HNR-1303-F23/main/unit-03/03-10-problem/fundraiser_sim.txt) contains the data from running our Monte-Carlo simulation dropping 100,000 balls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Read the data and plot the number of balls as a function of x-position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Fit a Gaussian curve to the number of balls as a function of x-position:\n",
    "$$y=A e^{\\left(-\\frac{1}{2}\\left(\\frac{x-B}{C}\\right)^2\\right)}$$\n",
    "where $y$ is the number of balls and $x$ is the x-position. Print the best-fit parameters (A,B,C) and plot the best-fit curve on the same graph as the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "In this model, the $A$ parameter is the only parameter that depends on the number of balls dropped. Every other parameter will remain the same as we change the number of balls dropped. We can break $A$ into two parts, $a$ and $N$:\n",
    "$$ A = aN $$\n",
    "where $N$ is the number of balls we are dropping and $a$ is the fraction of all balls dropped that land at x-position 0.\n",
    "\n",
    "What is the value of $a$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Suppose in the fundraiser we end up selling 1,000 ball drops. Using your answer from the previous exercise, what do we expect the value of $A$ to be? What do you expect the value of $B$ and $C$ to be? \n",
    "\n",
    "Note: In this exercise you should not be doing any fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "[This file](https://raw.githubusercontent.com/anthoak13/HNR-1303-F23/main/unit-03/03-10-problem/fundraiser_sim_1000.txt) contains the results of running the monte-carlo simulation dropping 1000 balls. Using your answers for the expected model parameters in the previous exercise, plot the prediction of the model and the data on the same graph for a fundraiser where 1000 balls are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In language, it is often the case that the most common word occurs about twice as often as the second most common word, about three times as often as the third most common word, etc. If we were to take every word in English and sort them by how frequently they occur, the *rank* of a word is its position in this ordered list. That is, the most common word has rank 1, the second most common has rank 2, etc. This [file](https://raw.githubusercontent.com/anthoak13/HNR-1303-F23/main/unit-03/03-10-problem/english_words.txt) contains the 1500 most common words in English ranked by how frequently they occur. The data comes from scraping one million sentences off of websites with a ``.com`` domain ([source](https://wortschatz.uni-leipzig.de/en/download)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Read the data into a `dataframe` and print the first few rows in the file using the `head()` function. Do not try to copy and paste the data (there is too much of it). What is the most common word in English? What is the second most common word in English?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Plot the frequency of words in English as a function of their rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Fit a curve to the frequency of words as a function of their rank using the following power law:\n",
    "\n",
    "$$ y = \\frac{A}{(x+B)^n}$$\n",
    "where $y$ is the frequency of a word and $x$ is the rank of the word. A power law distribution of this form is known as a [Zipf-Mandelbrot law](https://en.wikipedia.org/wiki/Zipf%E2%80%93Mandelbrot_law). Print the best-fit parameters ($A$, $B$, and $n$) and plot the best-fit curve on the same graph as the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "With the large spread of values on the y-axis, it is hard to see how well the model and data are agreeing at higher ranks. Fill in the following table with the prediction of your model for the frequency of words. You can use your graph or you can calculate your prediction with your model. **As the rank of the word increases how does the accuracy of our model change?**\n",
    "\n",
    "\n",
    "If you want to graph data within a certain range, you can use:\n",
    "\n",
    "```\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "```\n",
    "\n",
    "where `xmin`, `xmax`, `ymin`, and `ymax` are the minimum and maximum values on the x and y axes, respectively.\n",
    "\n",
    "Note: The **percent difference** is the difference between the actual and predicted quantity divided by the actual quantity, expressed as a precentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Word|Rank|Frequency|Predicted Frequency|% Difference|\n",
    "|---|---|---|---|---|\n",
    "|I|10|172807||\n",
    "|love|147|12071| |\n",
    "|every|166|10852| |\n",
    "|dog|1335|1572||\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Fit a curve to the frequency of words as a function of their rank using the Zipf-Mandelbrot law from Exercise 3 for words with a rank greater than 10. Plot the best-fit curve with the new fit parameters on the same graph as the data.\n",
    "\n",
    "Recall from the COVID exercise in a previous notebook how we can take a sub-range of data: \n",
    "\n",
    "```\n",
    "xdata2 = xdata[5:15]\n",
    "ydata2 = ydata[5:15]\n",
    "```\n",
    "\n",
    "Each list *includes* index 5 and *excludes* index 15. Thus, the data includes index 5 through index 14. If we want all data after and including index 5 we can write `xdata2 = xdata[5:]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "Fill in the following table with the prediction of your model from Exercise 6. You can use your graph or you can calculate your prediction with your model. **As the rank of the word increases how does the accuracy of our model change? Around what rank does our new model start underpredicting the frequency of words?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Word|Rank|Frequency|Predicted Frequency|% Difference|\n",
    "|---|---|---|---|---|\n",
    "|I|10|172807| |\n",
    "|love|147|12071| |\n",
    "|every|166|10852| |\n",
    "|dog|1335|1572| |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
